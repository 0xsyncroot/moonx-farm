# ğŸ“¦ Price Crawler Worker Specification

## ğŸ§  Objective

Develop a scalable **Price Crawler Worker** system that:

- Periodically collects **price**, **metadata**, and **audit** information for tokens.
- Fetches data from **Binance API**, **DexScreener**, and other CEX/DEX sources.
- Sends jobs via **Kafka** to worker services.
- Stores results in **PostgreSQL** with upsert logic.
- Supports real-time pricing for trading UI and backend order logic (Limit/DCA).

---

## ğŸ§± System Architecture

```
[SCHEDULER - node-cron]
   â†’ [Kafka Producer - node-rdkafka]
      â†’ Kafka Topics
         â†’ [Worker - Kafka Consumer (per job type)]
             â†’ [API Calls â†’ Transformation â†’ PostgreSQL]
```

Each (token type + job type) is handled by **independent pipelines** to support modular scaling and failure isolation.

---

## â±ï¸ Job Schedule Requirements

| Token Type   | Job Type    | Frequency     | Notes                                 |
|--------------|-------------|---------------|---------------------------------------|
| Top 100      | Metadata    | Every 24h     | Static metadata, fetched rarely       |
| Top 100      | Price       | Every 5 sec   | High frequency for trading UI         |
| Trending     | Price+Meta  | Every 1 min   | Fetched together                      |
| Trending     | Audit       | After price/meta | Executed immediately after completion |

---

## ğŸ“¦ Kafka Topic Design

| Topic Name                          | Purpose                        |
|------------------------------------|--------------------------------|
| `price-crawler.price.request`      | Price crawling jobs            |
| `price-crawler.metadata.request`   | Metadata crawling jobs         |
| `price-crawler.audit.request`      | Audit crawling jobs            |

**Kafka Message Structure:**

```json
{
  "job_type": "price",
  "token_type": "top100",
  "symbols": ["BTC", "ETH", "SOL"],
  "timestamp": "2025-06-25T21:00:00Z"
}
```

---

## âš™ï¸ Backend Stack

| Layer          | Technology                         |
|----------------|-------------------------------------|
| Scheduler      | `node-cron`                        |
| Messaging      | Kafka + `node-rdkafka`             |
| Worker         | `Node.js` + `TypeScript`           |
| API Client     | `axios` or `node-fetch`            |
| DB Access      | `Prisma` or `Knex.js`              |
| Database       | PostgreSQL                         |

---

## ğŸ” Business Rules

- Prices must always be fetched against **USDT**
- **Stablecoins** (e.g. USDT, USDC, DAI, WETH) are excluded
- Data is **overwritten** if a token contract already exists
- Use **contract address** as the primary key
- Audit jobs are executed **after** metadata/price for trending tokens

---

## ğŸ—ƒï¸ Database Schema

### ğŸ”¸ `tokens` (Token Metadata)

```sql
CREATE TABLE tokens (
  contract         VARCHAR(255) PRIMARY KEY,
  symbol           VARCHAR(50) NOT NULL,
  name             VARCHAR(255),
  chain_id         VARCHAR(50),
  decimals         INT,
  logo_url         TEXT,
  source           VARCHAR(100),
  is_stablecoin    BOOLEAN DEFAULT FALSE,
  last_updated_at  TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

### ğŸ”¸ `token_prices` (Price Tracking)

```sql
CREATE TABLE token_prices (
  id               SERIAL PRIMARY KEY,
  contract         VARCHAR(255) REFERENCES tokens(contract),
  price_usdt       NUMERIC(30, 10) NOT NULL,
  source           VARCHAR(100),
  timestamp        TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
  UNIQUE (contract, timestamp)
);
```

---

### ğŸ”¸ `token_audits` (Trending Token Audits)

```sql
CREATE TABLE token_audits (
  id               SERIAL PRIMARY KEY,
  contract         VARCHAR(255) REFERENCES tokens(contract),
  audit_score      NUMERIC(5,2),
  audit_provider   VARCHAR(255),
  is_verified      BOOLEAN,
  report_url       TEXT,
  created_at       TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

### ğŸ”¸ `job_logs` (Optional Monitoring)

```sql
CREATE TABLE job_logs (
  id               SERIAL PRIMARY KEY,
  job_type         VARCHAR(50),
  token_type       VARCHAR(50),
  contract         VARCHAR(255),
  status           VARCHAR(20),
  message          TEXT,
  executed_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## ğŸ” Index Recommendations

```sql
CREATE INDEX idx_tokens_symbol ON tokens(symbol);
CREATE INDEX idx_prices_contract_time ON token_prices(contract, timestamp DESC);
CREATE INDEX idx_audits_contract ON token_audits(contract);
CREATE INDEX idx_joblog_contract ON job_logs(contract);
```

---

## ğŸ“Œ Implementation Goals for AI Agent

- [ ] Generate scheduler job definitions (using `node-cron`)
- [ ] Implement Kafka producer for dispatching jobs
- [ ] Setup consumer pipelines per job type (price, metadata, audit)
- [ ] Implement data fetchers from Binance, DexScreener
- [ ] Normalize & transform data
- [ ] Connect to PostgreSQL using Prisma/Knex (In Progress)
- [ ] Use upsert logic on contract key (In Progress)
- [ ] Add retry, error logging, and healthcheck endpoints
- [ ] Optional: Docker + Compose setup for Kafka/PostgreSQL

## ğŸš€ Current Implementation Progress

---

### Tiáº¿n Ä‘á»™ cÃ¡c giai Ä‘oáº¡n

- **Giai Ä‘oáº¡n 1: Khung code & cáº¥u trÃºc dá»± Ã¡n** â€” 100% hoÃ n thÃ nh
- **Giai Ä‘oáº¡n 2: Scheduler & Job Definition** â€” 100% hoÃ n thÃ nh
- **Giai Ä‘oáº¡n 3: Kafka Producer/Consumer, tÃ­ch há»£p end-to-end** â€” 100% hoÃ n thÃ nh


## ğŸ› ï¸ Deployment Roadmap (Káº¿ hoáº¡ch triá»ƒn khai chi tiáº¿t)

### Giai Ä‘oáº¡n 1: Khung code & cáº¥u trÃºc dá»± Ã¡n
- **Má»¥c tiÃªu:** Táº¡o Ä‘áº§y Ä‘á»§ cÃ¡c file, module, class, interface chÃ­nh cho toÃ n bá»™ luá»“ng, chÆ°a cáº§n code logic chi tiáº¿t.
- **Äáº§u ra:** 
  - ThÆ° má»¥c, file cho tá»«ng thÃ nh pháº§n: Scheduler, Kafka Producer, Kafka Consumer (Worker), API Client, DB Access, Models, Config, Logger, Healthcheck.
  - Äá»‹nh nghÄ©a interface/class rá»—ng, comment mÃ´ táº£ vai trÃ².
  - Äáº£m báº£o Ä‘á»§ cÃ¡c pipeline cho tá»«ng loáº¡i job (price, metadata, audit).
- **TiÃªu chÃ­ hoÃ n thÃ nh:** Review cáº¥u trÃºc, xÃ¡c nháº­n Ä‘á»§ thÃ nh pháº§n, sáºµn sÃ ng cho code chi tiáº¿t.

### Giai Ä‘oáº¡n 2: Scheduler & Job Definition
- **Má»¥c tiÃªu:** CÃ i Ä‘áº·t Scheduler (node-cron), Ä‘á»‹nh nghÄ©a cÃ¡c loáº¡i job, lá»‹ch cháº¡y, mapping vá»›i Kafka Topic.
- **Äáº§u ra:** 
  - File scheduler vá»›i cÃ¡c cronjob cho tá»«ng loáº¡i token/job.
  - Äá»‹nh nghÄ©a cáº¥u trÃºc job, mapping vá»›i Kafka message.
- **TiÃªu chÃ­ hoÃ n thÃ nh:** CÃ³ thá»ƒ táº¡o job vÃ  gá»­i message máº«u lÃªn Kafka (chÆ°a cáº§n worker xá»­ lÃ½).

### Giai Ä‘oáº¡n 3: Kafka Producer/Consumer
- **Má»¥c tiÃªu:** 
  - CÃ i Ä‘áº·t Kafka Producer gá»­i job lÃªn topic.
  - CÃ i Ä‘áº·t Kafka Consumer cho tá»«ng loáº¡i job (price, metadata, audit).
- **Äáº§u ra:** 
  - Module producer, consumer, config káº¿t ná»‘i Kafka.
  - Worker nháº­n message, log ra console (chÆ°a xá»­ lÃ½ logic).
- **TiÃªu chÃ­ hoÃ n thÃ nh:** CÃ³ thá»ƒ gá»­i/nháº­n message giá»¯a scheduler vÃ  worker.

### Giai Ä‘oáº¡n 4: Data Fetcher & API Integration
- **Má»¥c tiÃªu:** 
  - CÃ i Ä‘áº·t cÃ¡c hÃ m fetch dá»¯ liá»‡u tá»« Binance, DexScreener, cÃ¡c nguá»“n CEX/DEX.
  - Chuáº©n hÃ³a dá»¯ liá»‡u Ä‘áº§u ra.
- **Äáº§u ra:** 
  - Module fetcher, mock API call, tráº£ vá» dá»¯ liá»‡u máº«u.
  - Äá»‹nh nghÄ©a interface dá»¯ liá»‡u chuáº©n.
- **TiÃªu chÃ­ hoÃ n thÃ nh:** Worker cÃ³ thá»ƒ gá»i fetcher, nháº­n dá»¯ liá»‡u máº«u.

### Giai Ä‘oáº¡n 5: Database Access & Upsert Logic
- **Má»¥c tiÃªu:** 
  - Káº¿t ná»‘i PostgreSQL qua Prisma/Knex.
  - CÃ i Ä‘áº·t upsert cho báº£ng tokens, token_prices, token_audits.
- **Äáº§u ra:** 
  - Module DB, hÃ m upsert, migration schema.
- **TiÃªu chÃ­ hoÃ n thÃ nh:** Worker lÆ°u dá»¯ liá»‡u máº«u vÃ o DB.

### Giai Ä‘oáº¡n 6: Xá»­ lÃ½ logic tá»«ng loáº¡i Job
- **Má»¥c tiÃªu:** 
  - CÃ i Ä‘áº·t chi tiáº¿t pipeline cho tá»«ng loáº¡i job: price, metadata, audit.
  - Äáº£m báº£o audit cháº¡y sau price/meta vá»›i trending token.
- **Äáº§u ra:** 
  - Worker xá»­ lÃ½ Ä‘á»§ cÃ¡c loáº¡i job, flow hoÃ n chá»‰nh.
- **TiÃªu chÃ­ hoÃ n thÃ nh:** End-to-end flow cho tá»«ng loáº¡i job.

### Giai Ä‘oáº¡n 7: Error Handling, Retry, Logging
- **Má»¥c tiÃªu:** 
  - ThÃªm retry, error log, lÆ°u job_logs.
- **Äáº§u ra:** 
  - Module logging, error handler, lÆ°u log vÃ o DB.
- **TiÃªu chÃ­ hoÃ n thÃ nh:** CÃ³ thá»ƒ theo dÃµi tráº¡ng thÃ¡i job, retry khi lá»—i.

### Giai Ä‘oáº¡n 8: Healthcheck & Monitoring
- **Má»¥c tiÃªu:** 
  - ThÃªm endpoint healthcheck, metric cÆ¡ báº£n.
- **Äáº§u ra:** 
  - Endpoint kiá»ƒm tra tráº¡ng thÃ¡i service.
- **TiÃªu chÃ­ hoÃ n thÃ nh:** CÃ³ thá»ƒ kiá»ƒm tra health qua HTTP.

### Giai Ä‘oáº¡n 9: Docker Compose & Deployment
- **Má»¥c tiÃªu:** 
  - Viáº¿t docker-compose cho Kafka, PostgreSQL, worker.
- **Äáº§u ra:** 
  - File docker-compose, hÆ°á»›ng dáº«n cháº¡y local.
- **TiÃªu chÃ­ hoÃ n thÃ nh:** CÃ³ thá»ƒ cháº¡y toÃ n bá»™ há»‡ thá»‘ng local.

### Giai Ä‘oáº¡n 10: Refactor, Test, Document
- **Má»¥c tiÃªu:** 
  - Refactor code, bá»• sung test, hoÃ n thiá»‡n tÃ i liá»‡u.
- **Äáº§u ra:** 
  - Unit test, integration test, tÃ i liá»‡u hÆ°á»›ng dáº«n.
- **TiÃªu chÃ­ hoÃ n thÃ nh:** Äáº£m báº£o code sáº¡ch, dá»… báº£o trÃ¬, cÃ³ test/tÃ i liá»‡u.

---
