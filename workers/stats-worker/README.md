# Stats Worker Service

**Pure Background Worker** Ä‘á»ƒ thu tháº­p vÃ  publish stats cho MoonX Farm platform.

## ğŸš€ TÃ­nh nÄƒng

- **Pure Background Worker**: KhÃ´ng cÃ³ HTTP server, chá»‰ táº­p trung vÃ o data collection
- **Chain Performance Monitoring**: Theo dÃµi block time, network performance vá»›i metadata Ä‘áº§y Ä‘á»§
- **Chain Metadata Collection**: Thu tháº­p chainSlug, logoUrl tá»« GitHub/CDN Ä‘Ã¡ng tin cáº­y
- **Bridge Latency Tracking**: Äo Ä‘á»™ trá»… cá»§a cÃ¡c bridge aggregator (LI.FI, Relay.link)
- **Stats Aggregation**: Thu tháº­p vÃ  lÆ°u trá»¯ thá»‘ng kÃª vÃ o MongoDB vá»›i schema má»Ÿ rá»™ng
- **Kafka Event Publishing**: Publish stats updates qua Kafka cho WebSocket service
- **Cronjob Scheduling**: Tá»± Ä‘á»™ng thu tháº­p stats theo schedule Ä‘á»‹nh sáºµn
- **Cluster Mode**: Production-ready vá»›i multiple worker processes
- **Health Monitoring**: Process-based health checks vÃ  logging
- **Flexible Chain Configuration**: Support nhiá»u chains vá»›i logo URLs cÃ³ thá»ƒ customize

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
workers/stats-worker/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”œâ”€â”€ index.ts              # Types cho stats data
â”‚   â”‚   â””â”€â”€ events.ts             # Event types cho WebSocket
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ statsModels.ts        # MongoDB models
â”‚   â”‚   â””â”€â”€ index.ts              # Model exports
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ chainStatsService.ts  # Chain performance collection
â”‚   â”‚   â”œâ”€â”€ bridgeStatsService.ts # Bridge latency collection
â”‚   â”‚   â”œâ”€â”€ statsAggregator.ts    # Stats aggregation logic
â”‚   â”‚   â””â”€â”€ eventPublisher.ts     # Kafka event publishing
â”‚   â”œâ”€â”€ jobs/
â”‚   â”‚   â”œâ”€â”€ statsCollector.ts     # Stats collection implementation
â”‚   â”‚   â””â”€â”€ scheduler.ts          # Job scheduling
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ logger.ts             # Logging utilities
â”‚   â”‚   â””â”€â”€ helpers.ts            # Helper functions
â”‚   â”œâ”€â”€ cluster.ts                # Cluster management
â”‚   â””â”€â”€ index.ts                  # Main entry point
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh                  # Automated setup script
â”‚   â”œâ”€â”€ start.sh                  # Production start script
â”‚   â”œâ”€â”€ dev.sh                    # Development start script
â”‚   â””â”€â”€ health-check.sh           # Health check script
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ env.template                  # Environment template
â”œâ”€â”€ docker-compose.yml            # Docker setup
â”œâ”€â”€ Dockerfile                    # Container image
â”œâ”€â”€ README.md                     # Documentation
â””â”€â”€ QUICK_START.md               # Quick start guide
```

## ğŸ”§ Environment Variables

```env
# Service Configuration
NODE_ENV=development
SERVICE_NAME=stats-worker
SERVICE_VERSION=1.0.0
# No PORT needed for background worker

# Cluster Configuration
CLUSTER_MODE=false
CLUSTER_WORKERS=0

# MongoDB Configuration
MONGODB_URI=mongodb://localhost:27017/moonx-farm
MONGODB_DATABASE=moonx-farm
MONGODB_MAX_POOL_SIZE=10
MONGODB_MIN_POOL_SIZE=1
MONGODB_ENABLE_METRICS=true

# Kafka Configuration
KAFKA_BROKERS=localhost:9092
KAFKA_CLIENT_ID=stats-worker
KAFKA_GROUP_ID=stats-worker-group
KAFKA_TOPIC_EVENTS=moonx.ws.events

# Chain RPC Configuration
ALCHEMY_API_KEY=your_alchemy_api_key_here
BASE_RPC_URL=https://base-mainnet.g.alchemy.com/v2/your_key
BSC_RPC_URL=https://bnb-mainnet.g.alchemy.com/v2/your_key
ETHEREUM_RPC_URL=https://eth-mainnet.g.alchemy.com/v2/your_key

# Cronjob Intervals
STATS_COLLECTION_INTERVAL=0 */5 * * * * # Every 5 minutes
CHAIN_PERFORMANCE_INTERVAL=0 */1 * * * * # Every 1 minute
BRIDGE_LATENCY_INTERVAL=0 */2 * * * * # Every 2 minutes

# External APIs
DEFILLAMA_API_URL=https://api.llama.fi
LIFI_API_URL=https://li.quest/v1
RELAY_API_URL=https://api.relay.link
```

## ğŸš€ Cháº¡y service

### Quick Start
```bash
# Automated setup
./scripts/setup.sh

# Start service
npm start
```

### Manual Setup
```bash
# Development
cp env.template .env
npm install
npm run dev

# Production
npm run build
npm start

# Docker
docker-compose up -d

# With environment file
docker run --env-file .env stats-worker
```

## ğŸ”— Cluster Mode

Service há»— trá»£ cluster mode Ä‘á»ƒ tÄƒng performance vÃ  reliability:

```bash
# Enable cluster mode
export CLUSTER_MODE=true
export CLUSTER_WORKERS=4
npm start

# Hoáº·c sá»­ dá»¥ng environment variables
CLUSTER_MODE=true CLUSTER_WORKERS=4 npm start
```

## ğŸ“Š Stats Data Structure

### Chain Performance Stats
```json
{
  "chainId": 8453,
  "chainName": "Base",
  "blockTime": {
    "current": 2.05,
    "change": "+0.12%",
    "changePercent": 0.12,
    "timestamp": 1234567890
  },
  "volume24h": "$125.5M",
  "volumeUSD": 125500000,
  "status": "healthy",
  "updatedAt": "2024-01-01T00:00:00Z"
}
```

### Bridge Latency Stats
```json
{
  "provider": "LI.FI",
  "latency": 850,
  "status": "healthy",
  "timestamp": 1234567890,
  "route": "Base->BSC",
  "fromChain": 8453,
  "toChain": 56,
  "updatedAt": "2024-01-01T00:00:00Z"
}
```

## ğŸ”„ Event Publishing

Worker publish cÃ¡c events sau qua Kafka:

- `stats.chain_performance_updated`
- `stats.bridge_latency_updated`
- `stats.overview_updated`

WebSocket service sáº½ consume vÃ  forward events nÃ y tá»›i frontend.

## ğŸ“ˆ Health Monitoring

### Process-based Health Checks
```bash
# Check if worker is running
ps aux | grep stats-worker

# Check Docker container
docker ps | grep stats-worker

# Check logs
tail -f logs/stats-worker.log
```

### Expected Log Output
```
[INFO] Stats Worker started in cluster mode
[INFO] Worker 1234 started
[INFO] Scheduled job: stats-collection
[INFO] Chain stats collected: Base, BSC, Ethereum
[INFO] Bridge latency collected: LI.FI, Relay.link
```

## ğŸ› ï¸ Development

### Scripts
```bash
npm start          # Start production service
npm run dev        # Start development service
npm run build      # Build TypeScript
npm test           # Run tests
npm run lint       # Run ESLint
```

### Helper Scripts
```bash
./scripts/start.sh           # Start production service
./scripts/dev.sh             # Start development service
./scripts/health-check.sh    # Check service health
```

## ğŸ³ Docker Deployment

```bash
# Start all services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f stats-worker

# Stop services
docker-compose down
```

## ğŸ” Troubleshooting

### Common Issues

1. **MongoDB Connection**
   ```bash
   # Check if MongoDB is running
   docker ps | grep mongo
   ```

2. **Kafka Connection**
   ```bash
   # Check if Kafka is running
   docker ps | grep kafka
   ```

3. **Alchemy API Rate Limit**
   ```bash
   # Check API key
   grep ALCHEMY_API_KEY .env
   ```

### Log Levels
```bash
# Debug mode
LOG_LEVEL=debug npm run dev

# Production logging
LOG_LEVEL=info npm start
```

## ğŸ—ï¸ Architecture

```
Stats Worker (Background Process)
â”œâ”€â”€ Cluster Manager
â”‚   â”œâ”€â”€ Worker Process 1
â”‚   â”œâ”€â”€ Worker Process 2
â”‚   â””â”€â”€ Worker Process N
â”œâ”€â”€ Job Scheduler
â”‚   â”œâ”€â”€ Stats Collection Job
â”‚   â”œâ”€â”€ Chain Performance Job
â”‚   â””â”€â”€ Bridge Latency Job
â”œâ”€â”€ Data Collection
â”‚   â”œâ”€â”€ Chain Stats Service
â”‚   â”œâ”€â”€ Bridge Stats Service
â”‚   â””â”€â”€ Stats Aggregator
â””â”€â”€ Data Output
    â”œâ”€â”€ MongoDB Storage
    â””â”€â”€ Kafka Event Publishing
```

## ğŸ“ Integration

### WebSocket Service Integration
Stats Worker publishs events qua Kafka, WebSocket service consume vÃ  forward:

```bash
# Kafka Topic: moonx.ws.events
# Event Types:
# - stats.chain_performance_updated
# - stats.bridge_latency_updated
# - stats.overview_updated
```

### Frontend Integration
Frontend connects tá»›i WebSocket service Ä‘á»ƒ receive real-time stats updates.

---

**Note**: ÄÃ¢y lÃ  pure background worker service, khÃ´ng cÃ³ HTTP API endpoints. Táº¥t cáº£ monitoring Ä‘Æ°á»£c thá»±c hiá»‡n qua logs vÃ  process checks. 